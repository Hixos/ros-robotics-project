***TEAM MEMBERS***
- Luca Erbetta (ID: 10537064, matr. number: 927617)


***INFO***

- Bag used for the map creation:
    2020-05-14-16-14-37-traj2-os1-t265-pix.bag
    (only used the first 70 seconds of the bag for map creation using optitrack odometry)

    Commands:
    - Optitrack: rosbag play --clock -u 70 2020-05-14-16-14-37-traj2-os1-t265-pix.bag
    - Visual: rosbag play --clock 2020-05-14-16-14-37-traj2-os1-t265-pix.bag

- Bag used for localization:
    2020-05-14-16-09-36-traj1-os1-t265-pix.bag

    Commands:
    - rosbag play --clock 2020-05-14-16-09-36-traj1-os1-t265-pix.bag

- Launch files
    launch/map_optitrack.launch: Mapping using optitrack odometry
    launch/map_visual.launch: Mapping using visual odometry
    launch/localization.launch: Localization using previously generated map

- Maps:
    maps/map_optitrack.yaml: Map created using optitrack odometry (only first room)
    maps/map_visual.yaml: Map created using visual odometry (used for localization)


***NODE CONFIGURATION DETAILS***

- pointcloud_to_laserscan
    - Set range_max to 120 to better represent the OS1 lidar range

- gmapping
    - Changed min and max parameters (ymin, xmin, ymax, xmax) to obtain a smaller map file
    - According to the documentation, we have to set maxUrange < Lidar range <= maxRange
      Because of this:
        . Set maxUrange to 100
        . Set maxRange to 120
    - Incresed map_update_interval to once every 2 seconds, to obtain a better 
      map at the cost of more computational power

- imu_complementary_filter
    Used mainly to obtain orientation data from the IMU, which is used by the 
    ekf_localization_node to remove the gravity vector from the accelerations.

    The imu topic used is /os1_cloud_node/imu. Filtered data is sent on /os1_cloud_node/imu_filt.

- robot_localization
    Node used to filter odometry data with readings from the IMU.
    2D mode was not used as 3D mode had better results, despite the robot moving 
    in a planar environement. This is most probably due to oscillations of the (tall) 
    robot, which are neglected in 2D mode.

    The odometry has been set to "relative" to account for different reported 
    starting position in the two bag files. In this way, the generated maps are 
    consistent between the two bags.

- amcl
    As reported in the ROS wiki, amcl with "odom_model_type" = "diff" has a bug 
    where it uses wrong unit conversions, so "diff-corrected" was used instead.

    Different configurations for parameters odom_alpha1-4 have been tested.
    Ultimately, we set an high noise for the translational component of the odometry, 
    ("odom_alpha3") due to the big drift after the robot enters in the second room.
    Setting an higher noise results in a better compensation of this drift.
    

***TF TREE***

List of most important tfs:

- Mapping using Optitrack
    map --> world: Generated by gmapping (used for drift correction)
    world --> Robot_1/base_link: Provided by the bag (odometry using optitrack)
    Robot_1/base_link --> os1_sensor: Static transform 

- Mapping using Visual odometry
    map --> camera_odom_frame: Generated by gmapping (used for drift correction)
    camera_odom_frame --> camera_pose_frame: Provided by the bag (odometry using optitrack)
    camera_odom_frame --> camera_pose_frame_filt: Filtered odometry generated by ekf_localization_node
    camera_pose_frame_filt --> os1_sensor: Static transform 

- Localization using amcl
    map --> camera_odom_frame: Generated by amcl (used for drift correction)
    camera_odom_frame --> camera_pose_frame: Provided by the bag (odometry using optitrack)
    camera_odom_frame --> camera_pose_frame_filt: Filtered odometry generated by ekf_localization_node
    camera_pose_frame_filt --> os1_sensor: Static transform 

